{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.table2graph import create_corpus, shuffle_vocabulary, build_graph_edges, build_node_features\n",
    "from utils.vectorize import generate_table_vectors\n",
    "from utils.evaluation import evaluate_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Dataset loading & Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=\"./datasets/benchmarks/rossman200.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pickle.load(open(dataset_path,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 17\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset),len(dataset[0][\"table\"].columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF = {\n",
    "    \"add_attr\":True,\n",
    "    \"shuffle_vocab\": True,\n",
    "    \"add_columns\":False,\n",
    "    \"vector_size\":50,\n",
    "    \"row_edges_sample\":0.5,\n",
    "    \"column_edges_sample\":0.05,\n",
    "    \"epoch_num\":10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific model settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF[\"n2v_walk_length\"] = 20\n",
    "CONF[\"n2v_context_size\"] = 10\n",
    "CONF[\"n2v_walks_per_node\"] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Build Table graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tables, vocabulary, cell_dict, reversed_dictionary = corpus_tuple = create_corpus(dataset,include_attr=CONF[\"add_attr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF[\"shuffle_vocab\"] == True:\n",
    "    shuffled_vocab = shuffle_vocabulary(vocabulary)\n",
    "else:\n",
    "    shuffled_vocab = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = build_node_features(vocabulary)\n",
    "row_edges_index, row_edges_weights = build_graph_edges(tokenized_tables,s_vocab=shuffled_vocab,sample_frac=CONF[\"row_edges_sample\"],columns=False)\n",
    "col_edges_index, col_edges_weights = build_graph_edges(tokenized_tables,s_vocab=shuffled_vocab,sample_frac=CONF[\"column_edges_sample\"],columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54596"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 928840])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_edges_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 351724])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_edges_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = torch.cat((row_edges_index,col_edges_index),dim=1)\n",
    "weights= torch.cat((row_edges_weights,col_edges_weights),dim=0)\n",
    "graph_data = Data(x=nodes,edge_index=edges,edge_attr=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 ) Run Table Auto-Encoder Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for VAE we split the edges to train/test\n",
    "def split_edges(graph_data):\n",
    "    graph_data.train_mask = graph_data.val_mask = graph_data.test_mask = graph_data.y = None\n",
    "    graph_data = train_test_split_edges(graph_data)\n",
    "    x, train_pos_edge_index = graph_data.x.to(device), graph_data.train_pos_edge_index.to(device)\n",
    "    return x, train_pos_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, train_pos_edge_index = split_edges(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_logvar = GCNConv(\n",
    "            2 * out_channels, out_channels, cached=True)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv_mu(x, edge_index), self.conv_logvar(x, edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=CONF[\"vector_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(graph_data.num_features, channels)\n",
    "model = VGAE(enc)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer,x, train_pos_edge_index):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    #loss = model.kl_loss()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def test(model,pos_edge_index, neg_edge_index,x, train_pos_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss10.2076 AUC: 0.8832, AP: 0.9208\n",
      "Epoch: 001, Loss6.0351 AUC: 0.8832, AP: 0.9208\n",
      "Epoch: 002, Loss4.6263 AUC: 0.8832, AP: 0.9205\n",
      "Epoch: 003, Loss4.3347 AUC: 0.8831, AP: 0.9204\n",
      "Epoch: 004, Loss4.1167 AUC: 0.8831, AP: 0.9205\n",
      "Epoch: 005, Loss3.8160 AUC: 0.8832, AP: 0.9207\n",
      "Epoch: 006, Loss3.5145 AUC: 0.8832, AP: 0.9207\n",
      "Epoch: 007, Loss3.2026 AUC: 0.8831, AP: 0.9208\n",
      "Epoch: 008, Loss2.9556 AUC: 0.8830, AP: 0.9208\n",
      "Epoch: 009, Loss2.7360 AUC: 0.8830, AP: 0.9207\n"
     ]
    }
   ],
   "source": [
    "losses=[]\n",
    "for epoch in range(CONF[\"epoch_num\"]):\n",
    "    loss = train(model,optimizer,x,train_pos_edge_index)\n",
    "    losses.append(loss)\n",
    "    auc, ap = test(model,graph_data.test_pos_edge_index, graph_data.test_neg_edge_index,x,train_pos_edge_index)\n",
    "    print('Epoch: {:03d}, Loss{:.4f} AUC: {:.4f}, AP: {:.4f}'.format(epoch,loss, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Extract the latent cell vectors, generate table vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_vectors(model,x,train_pos_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "        cell_vectors = z.numpy()\n",
    "    return z,cell_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "z,cell_vectors = get_cell_vectors(model,x,train_pos_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_list=generate_table_vectors(cell_vectors,tokenized_tables,s_vocab=shuffled_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_score=evaluate_model(dataset,vec_list,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41625"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[1280564], test_neg_edge_index=[2, 64028], test_pos_edge_index=[2, 64028], train_neg_adj_mask=[54596, 54596], train_pos_edge_index=[2, 1088480], val_neg_edge_index=[2, 32014], val_pos_edge_index=[2, 32014], x=[54596, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "table2vec",
   "language": "python",
   "name": "table2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
