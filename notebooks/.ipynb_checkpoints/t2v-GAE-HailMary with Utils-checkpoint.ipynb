{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import Node2Vec\n",
    "from torch_geometric.nn import GCNConv, GAE, VGAE\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.table2graph import create_corpus, shuffle_vocabulary, build_graph_edges, build_node_features\n",
    "from utils.vectorize import generate_table_vectors\n",
    "from utils.evaluation import evaluate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import (negative_sampling, remove_self_loops,\n",
    "                                   add_self_loops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Dataset loading & Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=\"./datasets/benchmarks/airlines50.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pickle.load(open(dataset_path,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 19\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset),len(dataset[0][\"table\"].columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF = {\n",
    "    \"add_attr\":True,\n",
    "    \"shuffle_vocab\": True,\n",
    "    \"add_columns\":False,\n",
    "    \"vector_size\":16,\n",
    "    \"row_edges_sample\":0.5,\n",
    "    \"column_edges_sample\":0.05,\n",
    "    \"epoch_num\":10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific model settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF[\"n2v_walk_length\"] = 20\n",
    "CONF[\"n2v_context_size\"] = 10\n",
    "CONF[\"n2v_walks_per_node\"] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Build Table graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tables, vocabulary, cell_dict, reversed_dictionary = corpus_tuple = create_corpus(dataset,include_attr=CONF[\"add_attr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF[\"shuffle_vocab\"] == True:\n",
    "    shuffled_vocab = shuffle_vocabulary(vocabulary)\n",
    "else:\n",
    "    shuffled_vocab = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = build_node_features(vocabulary)\n",
    "row_edges_index, row_edges_weights = build_graph_edges(tokenized_tables,s_vocab=shuffled_vocab,sample_frac=CONF[\"row_edges_sample\"],columns=False)\n",
    "col_edges_index, col_edges_weights = build_graph_edges(tokenized_tables,s_vocab=shuffled_vocab,sample_frac=CONF[\"column_edges_sample\"],columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_row_edges_index, all_row_edges_weights = build_graph_edges(tokenized_tables,s_vocab=shuffled_vocab,sample_frac=1.0,columns=False)\n",
    "all_col_edges_index, all_col_edges_weights = build_graph_edges(tokenized_tables,s_vocab=shuffled_vocab,sample_frac=1.0,columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possible_edges= torch.cat((all_row_edges_index,all_col_edges_index),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/benchmarks/airlines50.pickle\n"
     ]
    }
   ],
   "source": [
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13063 1001452 2273208 3274660\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes),all_row_edges_index.shape[1],all_col_edges_index.shape[1],all_possible_edges.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = torch.cat((row_edges_index,col_edges_index),dim=1)\n",
    "weights= torch.cat((row_edges_weights,col_edges_weights),dim=0)\n",
    "graph_data = Data(x=nodes,edge_index=edges,edge_attr=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def get_column_by_node(node,r_dict):\n",
    "    return r_dict[node][0]\n",
    "\n",
    "def get_column_ids(vocab,s_vocab=None):\n",
    "    if s_vocab is not None:\n",
    "        node_columns = [get_column_by_node(n,reversed_dictionary) for n in s_vocab]\n",
    "    else:\n",
    "        node_columns = [get_column_by_node(n,reversed_dictionary) for n in range(vocab)]\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    node_columns_ids = le.fit_transform(node_columns)\n",
    "    return torch.tensor(node_columns_ids,dtype=torch.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=get_column_ids(vocabulary,s_vocab=shuffled_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data.cols = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 ) Run Table Auto-Encoder Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for VAE we split the edges to train/test\n",
    "def split_edges(graph_data):\n",
    "    graph_data.train_mask = graph_data.val_mask = graph_data.test_mask = graph_data.y = None\n",
    "    graph_data = train_test_split_edges(graph_data)\n",
    "    x, train_pos_edge_index = graph_data.x.to(device), graph_data.train_pos_edge_index.to(device)\n",
    "    return x, train_pos_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, train_pos_edge_index = split_edges(graph_data)\n",
    "x, train_pos_edge_index = nodes,edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv_rows = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv_cols = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = GCNConv(4 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, row_edge_index,col_edge_index):\n",
    "        x1 = F.relu(self.conv_rows(x, row_edge_index))\n",
    "        x2 = F.relu(self.conv_cols(x, col_edge_index))\n",
    "        x_all = torch.cat((x1, x2), 1)\n",
    "        #print(x1.shape,x2.shape,x_all.shape)\n",
    "        edges = torch.cat((row_edges_index,col_edges_index),dim=1)\n",
    "        return self.conv2(x_all, edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=CONF[\"vector_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(graph_data.num_features, channels)\n",
    "model = GAE(enc)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(x, y=None):\n",
    "    '''\n",
    "    Input: x is a Nxd matrix\n",
    "           y is an optional Mxd matirx\n",
    "    Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n",
    "            if y is not given then use 'y=x'.\n",
    "    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
    "    '''\n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "    if y is not None:\n",
    "        y_norm = (y**2).sum(1).view(1, -1)\n",
    "    else:\n",
    "        y = x\n",
    "        y_norm = x_norm.view(1, -1)\n",
    "\n",
    "    dist = x_norm + y_norm - 2.0 * torch.mm(x, torch.transpose(y, 0, 1))\n",
    "    return dist\n",
    "    \n",
    "def get_column_loss(z):\n",
    "    avg_list = []\n",
    "    for i in range(len(dataset[0][\"table\"].columns)):\n",
    "        mask = (graph_data.cols == i)\n",
    "        avg_list.append(z[mask].mean(axis=0))\n",
    "    at= torch.stack(avg_list)\n",
    "    #distsum = euclidean_distances(at).sum()\n",
    "    distsum= pairwise_distances(at).sum()\n",
    "    #print(distsum)\n",
    "    return 20-torch.log(distsum)\n",
    "\n",
    "def get_column_loss2(z):\n",
    "    distsum=0\n",
    "    for i in range(len(dataset[0][\"table\"].columns)):\n",
    "        mask = (graph_data.cols == i)\n",
    "        colsum = pairwise_distances(z[mask]).sum()\n",
    "        #print(colsum)\n",
    "        distsum+=colsum\n",
    "    return torch.log(distsum)\n",
    "\n",
    "\n",
    "def recon_loss2(model,z, pos_edge_index,all_possible_edges):\n",
    "    r\"\"\"Given latent variables :obj:`z`, computes the binary cross\n",
    "    entropy loss for positive edges :obj:`pos_edge_index` and negative\n",
    "    sampled edges.\n",
    "\n",
    "    Args:\n",
    "        z (Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "        pos_edge_index (LongTensor): The positive edges to train against.\n",
    "    \"\"\"\n",
    "    EPS = 1e-15\n",
    "    MAX_LOGVAR = 10\n",
    "\n",
    "    pos_loss = -torch.log(\n",
    "        model.decoder(z, pos_edge_index, sigmoid=True) + EPS).mean()\n",
    "\n",
    "    # Do not include self-loops in negative samples\n",
    "    pos_edge_index, _ = remove_self_loops(pos_edge_index)\n",
    "    pos_edge_index, _ = add_self_loops(pos_edge_index)\n",
    "\n",
    "    neg_edge_index = negative_sampling(all_possible_edges, z.size(0))\n",
    "    neg_loss = -torch.log(1 -\n",
    "                          model.decoder(z, neg_edge_index, sigmoid=True) +\n",
    "                          EPS).mean()\n",
    "\n",
    "    return pos_loss + neg_loss\n",
    "\n",
    "\n",
    "def train(model,optimizer,x, row_edges,col_edges):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, row_edges,col_edges)\n",
    "    r1 = model.recon_loss(z, row_edges)\n",
    "    r2 = model.recon_loss(z,col_edges)\n",
    "    \n",
    "    edges = torch.cat((row_edges_index,col_edges_index),dim=1)\n",
    "    rl2 =recon_loss2(z,edges,all_possible_edges)\n",
    "    #row_loss = recon_loss2(model,z,row_edges,all_possible_edges)\n",
    "    #col_loss = recon_loss2(model,z,col_edges,all_possible_edges)\n",
    "    #kl = model.kl_loss()\n",
    "    #cl1 = get_column_loss(z)\n",
    "    #cl2 = get_column_loss2(z)\n",
    "    #loss=rl+cl2+kl\n",
    "    #loss = row_loss+col_loss\n",
    "    loss = rl2\n",
    "    \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #return loss,row_loss,col_loss\n",
    "    return loss\n",
    "\n",
    "\n",
    "def test(model,pos_edge_index, neg_edge_index,x, train_pos_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GAE' object has no attribute 'recon_loss2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d187559fd0f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch_num\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#loss,row_loss,col_loss = train(model,optimizer,x,row_edges_index,col_edges_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow_edges_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol_edges_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-b56ec3bf034a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, x, row_edges, col_edges)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_edges_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol_edges_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mrl\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecon_loss2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_possible_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;31m#row_loss = recon_loss2(model,z,row_edges,all_possible_edges)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m#col_loss = recon_loss2(model,z,col_edges,all_possible_edges)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/table2vec/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GAE' object has no attribute 'recon_loss2'"
     ]
    }
   ],
   "source": [
    "losses=[]\n",
    "for epoch in range(CONF[\"epoch_num\"]):\n",
    "    #loss,row_loss,col_loss = train(model,optimizer,x,row_edges_index,col_edges_index)\n",
    "    loss = train(model,optimizer,x,row_edges_index,col_edges_index)\n",
    "\n",
    "    losses.append(loss)\n",
    "\n",
    "    #print('Epoch: {:03d}, Row Loss{:.4f} Col Loss: {:.4f}, Loss: {:.4f}'.format(epoch,row_loss,col_loss,loss))\n",
    "    print(epoch,loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Extract the latent cell vectors, generate table vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_vectors(model,x,row_edges_index,col_edges_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, row_edges_index,col_edges_index)\n",
    "        cell_vectors = z.numpy()\n",
    "    return z,cell_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z,cell_vectors = get_cell_vectors(model,x,row_edges_index,col_edges_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_list=generate_table_vectors(cell_vectors,tokenized_tables,s_vocab=shuffled_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_score=evaluate_model(dataset,vec_list,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "table2vec",
   "language": "python",
   "name": "table2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
